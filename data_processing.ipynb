{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   answer_id anon_id       L1  gender   semester  placement_test  course_id  \\\n",
      "0          1     eq0   Arabic    Male  2006_fall             NaN        149   \n",
      "1          2     am8     Thai  Female  2006_fall             NaN        149   \n",
      "2          3     dk5  Turkish  Female  2006_fall             NaN        115   \n",
      "3          4     dk5  Turkish  Female  2006_fall             NaN        115   \n",
      "4          5     ad1   Korean  Female  2006_fall             NaN        115   \n",
      "\n",
      "   level_id class_id  question_id  version  text_len  \\\n",
      "0         4        g            5        1       177   \n",
      "1         4        g            5        1       137   \n",
      "2         4        w           12        1        63   \n",
      "3         4        w           13        1         6   \n",
      "4         4        w           12        1        59   \n",
      "\n",
      "                                                text  \\\n",
      "0  I met my friend Nife while I was studying in a...   \n",
      "1  Ten years ago, I met a women on the train betw...   \n",
      "2  In my country we usually don't use tea bags. F...   \n",
      "3              I organized the instructions by time.   \n",
      "4  First, prepare a port, loose tea, and cup.\\nSe...   \n",
      "\n",
      "                                              tokens  \\\n",
      "0  ['I', 'met', 'my', 'friend', 'Nife', 'while', ...   \n",
      "1  ['Ten', 'years', 'ago', ',', 'I', 'met', 'a', ...   \n",
      "2  ['In', 'my', 'country', 'we', 'usually', 'do',...   \n",
      "3  ['I', 'organized', 'the', 'instructions', 'by'...   \n",
      "4  ['First', ',', 'prepare', 'a', 'port', ',', 'l...   \n",
      "\n",
      "                                         tok_lem_POS  \n",
      "0  [('I', 'I', 'PRP'), ('met', 'meet', 'VBD'), ('...  \n",
      "1  [('Ten', 'ten', 'CD'), ('years', 'year', 'NNS'...  \n",
      "2  [('In', 'in', 'IN'), ('my', 'my', 'PRP$'), ('c...  \n",
      "3  [('I', 'I', 'PRP'), ('organized', 'organize', ...  \n",
      "4  [('First', 'first', 'RB'), (',', ',', ','), ('...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = \"/Users/jackyhe/Desktop/CS6741Final/PELIC_compiled.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46204"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>Can you give me a opinion about this matter?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>I own this car and this horse.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>Computer is the most useful invention for ever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Korean</td>\n",
       "      <td>My sister is acquiesce in a person's opinion.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Korean</td>\n",
       "      <td>A moment to call one's own at this class.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         L1                                               text\n",
       "35  Chinese       Can you give me a opinion about this matter?\n",
       "36  Chinese                     I own this car and this horse.\n",
       "37  Chinese  Computer is the most useful invention for ever...\n",
       "38   Korean      My sister is acquiesce in a person's opinion.\n",
       "39   Korean          A moment to call one's own at this class."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter rows based on the conditions\n",
    "filtered_df = df[\n",
    "    (df['L1'].isin(['Chinese', 'Arabic', 'Korean'])) & \n",
    "    (df['level_id'].isin([2, 3]))\n",
    "][['L1', 'text']]\n",
    "\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10395"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1\n",
      "Arabic     6429\n",
      "Chinese    2047\n",
      "Korean     1919\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "language_counts = filtered_df['L1'].value_counts()\n",
    "print(language_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          L1                                               text\n",
      "0     Arabic                                        my homework\n",
      "1     Arabic  Yes,because spanking a child is very bad way t...\n",
      "2     Arabic  I register in ELI by filling out there applica...\n",
      "3     Arabic  Now i am live with my friend in downtown, but ...\n",
      "4     Arabic  In the ELI, the activities vary according to t...\n",
      "...      ...                                                ...\n",
      "4495  Korean                            Does she use to live in\n",
      "4496  Korean  In my opinion, it is not always illegal thing....\n",
      "4497  Korean  Dae ANON_NAME_0 Kim has studied KOREA Unversit...\n",
      "4498  Korean  Topic: Look before you leap\\n\\nI used to work ...\n",
      "4499  Korean  Car is very usefull to people. It`s moved to u...\n",
      "\n",
      "[4500 rows x 2 columns]\n",
      "L1\n",
      "Arabic     1500\n",
      "Chinese    1500\n",
      "Korean     1500\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kk/c79wsldj45df2gtvh0ydth9m0000gn/T/ipykernel_83914/2389759078.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = filtered_df.groupby('L1').apply(lambda x: x.sample(n=1500, random_state=42)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# Randomly sample 1500 rows for each language\n",
    "sampled_df = filtered_df.groupby('L1').apply(lambda x: x.sample(n=1500, random_state=42)).reset_index(drop=True)\n",
    "\n",
    "print(sampled_df)\n",
    "print(sampled_df['L1'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 3600\n",
      "Test data size: 900\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = sampled_df['text']  # Feature (text)\n",
    "y = sampled_df['L1']    # Target (language)\n",
    "\n",
    "# Split the data into training (80%) and testing (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training data size: {len(X_train)}\")\n",
    "print(f\"Test data size: {len(X_test)}\")\n",
    "\n",
    "train_df = pd.DataFrame({'text': X_train, 'L1': y_train})\n",
    "test_df = pd.DataFrame({'text': X_test, 'L1': y_test})\n",
    "train_df.to_csv(\"/Users/jackyhe/Desktop/CS6741Final/data/train_data.csv\", index=False)\n",
    "test_df.to_csv(\"/Users/jackyhe/Desktop/CS6741Final/data/test_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langback",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
